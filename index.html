<!DOCTYPE HTML>
<!--
	Photon by HTML5 UPhould we
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>ML Pre-registration workshops</title>
		<meta charset="utf-8" />
		<link rel="canonical" href="https://preregister.science"/>
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<!-- Open Graph metadata (used when sharing on social media) -->
		<meta property="og:type" content="website" />
		<meta property="og:title" content="NeurIPS 2021 pre-registration workshop" />
		<meta property="og:description" content="Testing whether pre-registration can help fix our peer review system." />
		<meta property="og:url" content="https://preregister.science" />
		<meta property="og:image" content="https://preregister.science/images/header.jpg" />

	</head>
	<body class="is-preload">
		<!-- Header -->
		<section id="header">
			<div class="inner">
				<span class="icon major style0 fa fa-area-chart"></span>
				<h2>The <strong style="color:#FCCA46;">pre-registration workshop</strong>: <br>An alternative publication model for machine learning research</h2>
				<!-- <h4>At <a href="https://neurips.cc/" target="_blank">NeurIPS 2021</a>.</h4> -->
				<h4>Monday, December 13, 12:00-19:00 GMT</h4>
				<ul class="actions special">
					<li><a href="https://neurips.cc/virtual/2021/workshop/21885" class="button primary">Click to join us at NeurIPS 2021!</a></li>
				</ul>
			</div>
		</section>
        
		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style1 special">
			<div class="container">
				<header class="major">
					<h2>Pre-registration in a nutshell</h2>
				</header>
				<div class="container">
                    <h3>Separate the generation and confirmation of hypotheses:</h3>
					<h4><span class="icon fa-lightbulb-o"></span>&nbsp;&nbsp;&nbsp;Come up with an exciting research question&nbsp;&nbsp;&nbsp;<span class="icon fa-lightbulb-o"></span></h4>
					<h4><span class="icon fa-pencil"></span>&nbsp;&nbsp;&nbsp;Write a paper proposal without confirmatory experiments&nbsp;&nbsp;&nbsp;<span class="icon fa-pencil"></span></h4>
					<h4><span class="icon fa-flask"></span>&nbsp;&nbsp;&nbsp;After the paper is accepted, run the experiments and report your results&nbsp;&nbsp;&nbsp;<span class="icon fa-flask"></span></h4>
				</div>
			</div>
		</section>

		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style2">
			<div class="container">
				<div class="row gtr-0">
					<div class="col-3">
						<ul class="major-icons">
							<li><span class="icon major fa-balance-scale"></span></li>
						</ul>
					</div>
					<div class="col-9">
						<header class="major">
						<h2>What does <strong style="color:#FCCA46;">science</strong> get?</h2>
						</header>
						<ul>
							<li>A healthy mix of positive and negative results</li>
							<li>Reasonable ideas that don’t work still get published, avoiding wasteful replications</li>	
							<li>Papers are evaluated on the basis of scientific interest, not whether they achieve the best results</li>
						</ul>
					</div>
				</div>
				<div class="row gtr-0">
					<div class="col-3">
						<ul class="major-icons">
							<li><span class="icon major fa-rocket"></span></li>
						</ul>
					</div>
					<div class="col-9">
						<header class="major">
						<h2>What do <strong style="color:#FCCA46;">you</strong> get?</h2>
						</header>
						<ul>
							<li>It's easier to plan your research: get feedback before investing in lengthy experiments</li>
              <!--<li>Reviews that are not biased towards authors with an identical idea, but greater computational resources who have greater ability to cherry-pick.</li>-->
							<li>Your research is stronger: results have increased credibility</li>
							<!--<li>Your paper gets reviewed on the strength of your arguments and ideas, not numbers</li>-->
							<li>Convince people that they will learn something even if the result is negative</li>
							<!--<li>Unexpected findings can still be reported, but are not confused with hypothesis testing</li>-->
						</ul>
					</div>
				</div>
			</div>
		</section>

		
		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style1 special">
			<div class="container">
				<header class="major">
					<h2>Speakers</h2>
				</header>
				<div class="row">
					
					<div class="col-3 col-6-small off-2-xsmall col-8-xsmall">
						<span class="image fit circle"><img src="images/sarahanne.jpg" alt=""></span>
						<h3><a href="http://www.sarahannemfield.com/">Sarahanne Field</a></h3>
						<h5>University of Groningen</h5>
						<h5><q>Preregistration: Introduction and Application to ML</q></h5>
					</div>
					
					<div class="col-3 col-6-small off-2-xsmall col-8-xsmall">
						<span class="image fit circle"><img src="images/dima.jpg" alt=""></span>
						<h3><a href="http://people.cs.bris.ac.uk/~damen/">Dima Damen</a></h3>
						<h5>University of Bristol</h5>
						<h5><q>Defending the Undefendable - Why I support peer reviewing?</q></h5>
					</div>
					
					<div class="col-3 col-6-small off-2-xsmall col-8-xsmall">
						<span class="image fit circle"><img src="images/hugo.jpg" alt=""></span>
						<h3><a href="https://mila.quebec/en/person/hugo-larochelle/">Hugo Larochelle</a></h3>
						<h5>Google &amp; University of Montreal</h5>
						<h5><q>Transactions on Machine Learning Research: A New Open Journal for Machine Learning</q></h5>
					</div>
					
					<div class="col-3 col-6-small off-2-xsmall col-8-xsmall">
						<span class="image fit circle"><img src="images/smaldino.jpg" alt=""></span>
						<h3><a href="https://smaldino.com/wp/">Paul Smaldino</a></h3>
						<h5>UC Merced</h5>
						<h5><q>Preregistration: A Reasonably Good Idea In A Time of Crisis</q></h5>
					</div>
					
				</div>
			</div>
		</section>

		<!-- ------------------------------------------------------------------------------------------------------->
		
		<section class="main style2 special">
			<div class="container">
				<header class="major">
					<h2>Schedule (December 13)</h2>
				</header>
				
				<ul class="actions special">
					<li><a href="https://neurips.cc/virtual/2021/workshop/21885" class="button primary">Click to join us at NeurIPS 2021!</a></li>
				</ul>

				<div class="table-wrapper">
					<table id="schedule">
						<thead>
							<tr>
								<th id="schedule-timezone">Time (UTC)</th><th>Session</th><th>Duration</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>12:00</td><td>Opening Remarks</td><td>0:10</td>
							</tr>
							<tr>
								<td>12:10</td><td>Sarahanne Field (Invited Talk)<br><em>Preregistration: Introduction and Application to ML</em></td><td>0:30</td>
							</tr>
							<tr>
								<td>12:40</td><td>Oral Session 1<br><em>PCA Retargeting: Encoding Linear Shape Models as Convolutional Mesh Autoencoders (Eimear O'Sullivan)</em></td><td>0:20</td>
							</tr>
							<tr>
								<td>13:00</td><td>Spotlights 1 (5 x 3 min)</td><td>0:20</td>
							</tr>
							<tr>
								<td>13:20</td><td>Oral Session 2<br><em>Unsupervised Resource Allocation with Graph Neural Networks (Miles Cranmer)</em></td><td>0:20</td>
							</tr>
							<tr>
								<td>13:40</td><td>Break</td><td>0:30</td>
							</tr>
							<tr>
								<td>14:10</td><td>Dima Damen (Invited Talk)<br><em>Defending the Undefendable - Why I support peer reviewing?</em></td><td>0:30</td>
							</tr>
							<tr>
								<td>14:40</td><td>Hugo Larochelle (Invited Talk)<br><em>Transactions on Machine Learning Research: A New Open Journal for Machine Learning</em></td><td>0:30</td>
							</tr>
							<tr>
								<td>15:10</td><td>Spotlights 2 (5 x 3 min)</td><td>0:20</td>
							</tr>
							<tr>
								<td>15:30</td>
								<td>
									Poster Session
									<ul class="actions special">
										<li><a href="https://eventhosts.gather.town/app/F5CfZLXwNGasEmGR/prereg-posters" class="button">Click to join us at Gather.Town</a></li>
									</ul>
								</td>
								<td>1:00</td>
							</tr>
							<tr>
								<td>16:30</td><td>Break</td><td>0:30</td>
							</tr>
							<tr>
								<td>17:00</td><td>Paul Smaldino (Invited Talk)<br><em>Preregistration: A Reasonably Good Idea In A Time of Crisis</em></td><td>0:30</td>
							</tr>
							<tr>
								<td>17:30</td><td>Oral Session 3<br><em>Confronting Domain Shift in Trained Neural Networks (Carianne Martinez)</em></td><td>0:20</td>
							</tr>
							<tr>
								<td>17:50</td><td>2020 Authors' Experience (Discussion Panel)</td><td>0:15</td>
							</tr>
							<tr>
								<td>18:05</td><td>Open Discussion</td><td>1:00</td>
							</tr>
							<tr>
								<td>19:05</td><td>Closing Remarks</td><td>0:05</td>
							</tr>
						</tbody>
					</table>
				</div>
			</div>
		</section>

        <!-- ------------------------------------------------------------------------------------------------------->
        <section class="main style1">
        <div class="container">

        <div class="col-10-medium off-1-medium col-8-large off-2-large col-8-xlarge off-2-xlarge col-8-max off-2-max">
            <!--<p> </p>-->
            <header class="major special">
                <h2>Accepted proposals</h2>
								<p>Including a playlist of all 3-minute spotlight videos.</p>
            </header>
            
						<div class="video-wrapper">
                <iframe src="https://www.youtube-nocookie.com/embed/videoseries?list=PLB2hvs7du3_dNYh7JZY0-EUUrGDYFGpbl" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
						</div>

            <div class="table-wrapper">
                <table>
                    <tbody>
                        <tr>
                            <td>
                                <b>ID</b>
                            </td>
                            <td>
                                <b>Authors</b>
                            </td>
                            <td>
                                <b>Title</b>
                            </td>
                            <td>
                                <b>Proposal</b>
                            </td>
                            <td>
                                <b>Video</b>
                            </td>
                            <td>
                                <b>Poster</b>
                            </td>
                            <!--<td>
                                <b>Results</b>
                            </td>-->
                        </tr>
                        <tr>
                            <td>
                                3
                            </td>
                            <td>
                                Shubhaankar Gupta, Thomas P. O’Connell, Bernhard Egger
                            </td>
                            <td>
                                <em>
                                Beyond Flatland: Pre-training with a Strong 3D Inductive Bias
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/3_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/HslXCscx70o">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/3_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                6
                            </td>
                            <td>
                                Mikolaj Czerkawski, Javier Cardona, Robert Atkinson, Craig Michie, Ivan Andonovic, Carmine Clemente, Christos Tachtatzis
                            </td>
                            <td>
                                <em>
                                Neural Weight Step Video Compression
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/6_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/rF6ibyK2iSs">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/6_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                8
                            </td>
                            <td>
                                Hamid Eghbal-zadeh, Gerhard Widmer
                            </td>
                            <td>
                                <em>
                                How Much is an Augmented Sample Worth?
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/8_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/luq8SUnA2dw">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/8_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                10
                            </td>
                            <td>
                                Steven Lang, Martin Mundt, Fabrizio Ventola, Robert Peharz, Kristian Kersting
                            </td>
                            <td>
                                <em>
                                Elevating Perceptual Sample Quality in Probabilistic Circuits through Differentiable Sampling
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/10_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/8aTnMHtTIRc">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/10_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                11
                            </td>
                            <td>
                                Rohit Lal, Arihant Gaur, Aadhithya Iyer, Muhammed Abdullah Shaikh, Ritik Agrawal, Shital Chiddarwar
                            </td>
                            <td>
                                <em>
                                Open-Set Multi-Source Multi-Target Domain Adaptation
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/11_paper.pdf">Proposal</a>
                                <a href="papers_21neurips/11_suppl.pdf">Supmat</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/dflYL6WBZI4">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/11_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                15
                            </td>
                            <td>
                                Sebastian Palacio, Federico Raue, Tushar Karayil, Jörn Hees, Andreas Dengel
                            </td>
                            <td>
                                <em>
                                IteROAR: Quantifying the Interpretation of Feature Importance Methods
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/15_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/vEfd6jjlKQg">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/15_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                18
                            </td>
                            <td>
                                Kshitij Ambilduke, Aneesh Shetye, Diksha Bagade, Rishika Bhagwatkar, Khurshed Fitter, Prasad Vagdargi, Shital Chiddarwar
                            </td>
                            <td>
                                <em>
                                Enhancing Context Through Contrast
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/18_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/YCn96BDD-j8">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/18_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                19
                            </td>
                            <td>
                                Shuyang Li, Huanru Henry Mao, Julian McAuley
                            </td>
                            <td>
                                <em>
                                Variable Bitrate Discrete Neural Representations via Causal Self-Attention
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/19_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/hOdTeJv1a7Y">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/19_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                26
                            </td>
                            <td>
                                Pierre Thodoroff, Wenyu Li, Neil D. Lawrence
                            </td>
                            <td>
                                <em>
                                Benchmarking Real-Time Reinforcement Learning
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/26_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/UbQl0LxqFzo">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/26_poster.png">Poster</a>
                            </td>
                        </tr>
                        <tr>
                            <td>
                                29
                            </td>
                            <td>
                                Vaasudev Narayanan, Aniket Anand Deshmukh, Urun Dogan, Vineeth N Balasubramaniam
                            </td>
                            <td>
                                <em>
                                On Challenges in Unsupervised Domain Generalization
                                </em>
                            </td>
                            <td>
                                <a href="papers_21neurips/29_paper.pdf">Proposal</a>
                            </td>
                            <td>
                                <a href="https://youtu.be/KDQlb_0oEFg">Video</a>
                            </td>
                            <td>
                                <a href="posters_21neurips/29_poster.png">Poster</a>
                            </td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
        </div>
        </section>

		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style2">
			<div class="container">
				<header class="major special">
					<h2>Preregistration in more detail</h2>
				</header>
				<div class="container">
					<p>
						<strong>What is pre-registration and how does it improve peer-review?</strong>
						Benchmarks on popular datasets have played a key role in the considerable measurable progress that machine learning has made in the last few years.
						But reviewers can be tempted to prioritise incremental improvements in benchmarks to the detriment of other scientific criteria, destroying many good ideas in their infancy.
						Authors can also feel obligated to make orthogonal improvements in order to “beat the state-of-the-art”, making the main contribution hard to assess.
					</p>
					<p>
						Pre-registration changes the incentives by <i>reviewing and accepting a paper before experiments are conducted</i>.
						The emphasis of peer-review will be on whether the experiment plan can adequately prove or disprove one (or more) hypotheses.
						Some results will be negative, and this is welcomed.
						This way, good ideas that do not work will get published, instead of filed away and wastefully replicated many times by different groups.
						Finally, the clear separation between hypothesizing and confirmation (absent in the current review model) will raise the statistical significance of the results.
					</p>
					<p>
						<strong>Call for Papers:</strong>
						We are inviting submissions on the <a href="https://neurips.cc/Conferences/2021/CallForPapers"> range of topics covered at NeurIPS</a>!
						Pre-registered papers will be published at the workshop, which is non-archival.
						After NeurIPS, authors will have the opportunity to submit the results paper to the Proceedings of Machine Learning Research (<a href="http://proceedings.mlr.press/">PMLR</a>), a sister publication to the Journal of Machine Learning Research (<a href="https://www.jmlr.org/">JMLR</a>).
						(you can find last year's proceedings <a href="http://proceedings.mlr.press/v148/">here</a>).
						The review process for this second stage will aim to ensure that the authors have performed a good-faith attempt to complete the experiments described in their proposal paper.
					</p>
					</p>
				</div>
			</div>
		</section>

		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style1 special">
			<div class="container">
				<header class="major">
					<h2>Paper submission process</h2>
				</header>

            <div class="table-wrapper">
                <table style="text-align: left">
                    <tbody>
                        <tr>
							<td>&rarr; There are two phases. The first one involves the presentation of paper <i>proposals</i> and will conclude with NeurIPS 2021 workshop day.  The experiment phase will start after the acceptance of the proposals and will continue after the day of the workshop.</td>
                        </tr>
                        <tr>
							<td>&rarr; The deadline for the proposal is September the 19th. The deadline for the results is <strike>30th April</strike>, 7th May 2022 (23:59 AoE timezone).</td>
                        </tr>
						<tr>
							<td>&rarr; The proposal is non-archival and will be included in the workshop proceedings. The full papers, formed as the collation of proposal and results, will each published as a journal in a PMLR volume.</td>
						</tr>

						<tr>
							<td>&rarr; Please read our tutorial before submitting, which you can find <a href="https://preregister.science/author-kit/preregistration_tutorial.pdf">here</a>. The paper structure and general rationale is different to what you may be used to. Even if the proposals must not include experimental results, it is important to carefully design and describe the experimental protocol, with the aim of eventually obtaining conclusive results.</td>
						</tr>

						<tr>
							<td>&rarr; You can submit <a href="https://cmt3.research.microsoft.com/NeurIPSWSPrereg2021/">here via CMT</a>. For your proposals, please use our <a href="https://preregister.science/author-kit/neurips2021_preregistration_template.zip">modified NeurIPS template</a>.</td>
						</tr>
						<tr>
							<td>&rarr; For the proposal, the maximum length is five pages (references excluded). For the full papers there is not a strict limit, although we recommend to limit the experiments to a maximum extra four pages with respect to the proposal.</td>
						</tr>

						<tr>
							<td>&rarr; For inspiration, have a look at the other sections of this website, which provide further information. Moreover, you can find all the videos and proposals of last year edition <a href="https://preregister.science/neurips2020.html">here</a>, and the PMLR volume with the <i>full papers</i> from 2020 workshop <a href="http://proceedings.mlr.press/v148/">here</a>.</td>
						</tr>

                    </tbody>
                </table>
            </div>
			</div>
		</section>

        <!-- ------------------------------------------------------------------------------------------------------->
        <section class="main style2">
        <div class="container">

        <div class="col-10-medium off-1-medium col-8-large off-2-large col-8-xlarge off-2-xlarge col-8-max off-2-max">
            <!--<p> </p>-->
            <header class="major special">
                <h2>Paper submission dates</h2>
            </header>

            <div class="table-wrapper">
                <table>
                    <tbody>
                        <tr>
                            <td><h4>1) Proposal phase:</h4></td>
                            <td><h4>Selection of pre-registered papers for the NeurIPS Workshop</h4></td>
                        </tr>
                        <tr>
                            <td>&emsp;19th Sept 2021</td>
                            <td>&emsp;Paper submission <span style="color:DarkSeaGreen">(authors)</span></td>
                        </tr>
                        <tr>
                            <td>&emsp;20th Sept to 27th Sept 2021</td>
                            <td>&emsp;Review period <span style="color:#ff7b25">(reviewers)</span></td>
                        </tr>
                        <tr>
                            <td>&emsp;1st Oct to 8th Oct 2021</td>
                            <td>&emsp;Rebuttal period <span style="color:DarkSeaGreen">(authors)</span></td>
                        </tr>
                        <tr>
                            <td>&emsp;22nd Oct 2021</td>
                            <td>&emsp;Notification of decisions</td>
                        </tr>
                        <tr>
                            <td>&emsp;1st Dec 2021</td>
                            <td>&emsp;Camera ready submission <span style="color:DarkSeaGreen">(authors)</span></td>
                        </tr>
                        <tr>
                            <td>&emsp;13th Dec 2021</td>
                            <td>&emsp;NeurIPS 2021 workshop day</td>
                        </tr>
                            <td><h4>2) Results phase:</h4></td>
                            <td><h4>Selection of results papers for PMLR journal</h4></td>
                        </tr>
                        <tr>
                            <td>&emsp;<strike>30th April</strike>, 7th May 2022 (23:59 AoE timezone)</td>
                            <td>&emsp;Full paper (with results) submission <span style="color:DarkSeaGreen">(authors)</span></td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
        </div>
        </section>

		<!-- ------------------------------------------------------------------------------------------------------->
        <!--
		<section class="main style1">
			<div class="container">
				<header class="major">
					<h2>Important info and dates</h2>
				</header>
				<div>
					<p>The review cycle for a pre-registered study consists of two stages: the <strong>proposal paper</strong> and the <strong>results paper</strong>.
					These stages reflect the exploratory (hypothesis generation) and confirmatory (hypothesis testing) phases of research.</p>

					<h3>Proposal paper</h3>
                    <del>
					<ul>
						<li>Read our <a href="author-kit/neurips2020_preregistration_template.zip"><strong>mini-tutorial/template</strong></a> (<a href="author-kit/tutorial.pdf">PDF</a>) &mdash; it serves as a paper template, describes the submission process and the intended spirit of a pre-registration.</li>
						<li><strong>Submit</strong> your paper anonymously to <a href="https://cmt3.research.microsoft.com/NeurIPSWorkshopPrereg2020">CMT</a>.
							Differently from traditional submissions, the experimental section must only contain a description of experiments and protocol, and what conclusions can be drawn in different cases, without the results themselves.
                                                        The pre-registration proposal should use the <a href="author-kit/neurips2020_preregistration_template.zip">paper template</a>. 
							We recommend <strong>4 pages</strong>, but we allow up to 5 pages (excluding references) for the pre-registration proposal. Note that, for some venues, only papers up to 4 pages (without references) are not considered as 'prior submission', see e.g. <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines">CVPR</a>. For others, e.g. <a href="https://neurips.cc/Conferences/2020/PaperInformation/NeurIPS-FAQ">NeurIPS</a>, non-archival workshops like ours do not count as dual submissions. <strong>The deadline for submissions is <strong style="color:red">October <strike>7th</strike> 9th (midnight Anywhere on Earth: GMT + 12).</strong></strong>
						<li>Besides quality and potential impact of the idea, reviewers will also assess: (1) Are the experiments appropriate for validating the core hypothesis of the work?
						(2) Is the experimental protocol description sufficient to allow reproduction of the experiments?
						You will then have a <strong>rebuttal period (until October 22nd)</strong> to address the comments of the reviewers, by writing a short response.
						<li><strong>Decisions will be sent to authors by October 30th</strong>.</li>
						<li><strong>On the day of the workop (December 11th, <strong style="color:red">remote</strong>, from 9:20AM New York time))</strong>, authors will present their proposals and (optionally) their preliminary results.</li>
					</ul>
                    </del>

					<h3>Results paper</h3>
					<ul>
					<li>Authors carry out the experimental protocols proposed in their accepted proposal papers.
					<li>The results will be presented in second document known as the results paper.
						<strong>The results paper consists of just the &ldquo;experimental results&rdquo; and &ldquo;conclusions&rdquo; sections of standard publications</strong>.
					This will be appended to the proposal paper to form the complete document.
					The deadline for the results paper is going to be in <del>April, 2021 (tentative)</del> <strong style="color:red">The deadline has been extended to Friday 7th May, 23:59, Anywhere on Earth time zone.</strong></li>
					<li>We will then support and encourage the final results to be published at the <a href="http://proceedings.mlr.press/">PMLR</a> in combination with the pre-registered paper.</li>
					<li><del>In case of interest, we will also organise a second virtual meeting at the end of April 2021 to discuss the experimental results and the lesssons learned.</del> (to be determined)</li>
					</ul>
				</div>
			</div>
		</section>
        -->

		<section class="main style1 special">
			<div class="container">
				<header class="major">
					<h2>Organisers</h2>
				</header>
				<div class="row">

					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/samuel.jpg" alt="Samuel Albanie"></span>
						<h5><a href="https://www.robots.ox.ac.uk/~albanie/">Samuel Albanie</a></h5>
						<h5>University of Cambridge</h5>
					</div>

					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/joao.jpg" alt="Jo&atilde;o F. Henriques"></span>
						<h5><a href="https://www.robots.ox.ac.uk/~joao/">Jo&atilde;o F. Henriques</a></h5>
						<h5>University of Oxford</h5>
					</div>

<!--					<div class="off-1 col-2 off-0-medium col-4-medium">-->
					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/luca.jpg" alt="Luca Bertinetto"></span>
						<h5><a href="https://www.robots.ox.ac.uk/~luca/">Luca Bertinetto</a></h5>
						<h5>Five</h5>
					</div>

					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/alex.jpg" alt="Alex Hernandez-García"></span>
						<h5><a href="https://alexhernandezgarcia.github.io/">Alex Hernández-García</a></h5>
						<h5>Mila (Quebec AI Institute) and Université de Montréal</h5>
					</div>
					
					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/hazel.jpg" alt="Hazel Doughty"></span>
						<h5><a href="https://hazeldoughty.github.io/">Hazel Doughty</a></h5>
						<h5>University of Amsterdam</h5>
					</div>

					<div class="col-2 col-4-medium">
						<span class="image fit circle"><img src="images/gul.jpg" alt="G&uuml;l Varol"></span>
						<h5><a href="http://imagine.enpc.fr/~varolg/">G&uuml;l Varol</a></h5>
						<h5>École des Ponts ParisTech</h5>
					</div>
					
				</div>
            </div>
        </section>
				
		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style2 special">
			<div class="container">
				<header class="major">
					<h2>Reviewers</h2>
				</header>
				<p>Many thanks to all the reviewers for their help!</p>
				<div class="row">
					<div class="col-4 col-12-xsmall">
						Adrian      Javaloy <br>
						Adrian      Spurr<br>
						Alex        Hernandez Garcia<br>
						Andrew      Gambardella<br>
						Arnout      Devos<br>
						Ayush       Jaiswal<br>
						Bernardino  Romera-Paredes<br>
						Brad    J   Gram-Hansen<br>
						Carianne    Martinez<br>
						Cees        Snoek<br>
						Chaitanya   Devaguptapu<br>
						Chaoning    Zhang<br>
						Chen        Sun<br>
						David       Krueger <br>
						Dimitris    Tsipras <br>
						Disha       Shrivastava<br>
						Efstratios  Gavves<br>
						Emir        Konuk<br>
						Emmanuel    Bengio<br>
						Erika       Lu<br>
						Evangelos   Kazakos<br>
						Francesco   Ferroni <br>
						Francesco   Pinto<br>
						Francisco   Girbal Eiras
					</div>
					<div class="col-4 col-12-xsmall">
						Hadrien     Bertrand<br>
						Hamid       Eghbal-zadeh<br>
						Harkirat    Behl<br>
						Jack        Valmadre<br>
						James       Thornton<br>
						Jason   S.   Hartford<br>
						Joseph      Viviano<br>
						Konstantinos    Tertikas<br>
						Lénaïc        Chizat<br>
						Li      Shen<br>
						Liliane     Momeni<br>
						Malik   H.  Altakrori<br>
						Martin      Mundt<br>
						Mélisande  Teng<br>
						Michele     Svanera <br>
						Miguel-Ángel   Fernández-Torres<br>
						Nazanin M.   Sepahvand<br>
						Oriane      Siméoni<br>
						Paul        Rubenstein<br>
						Rishabh     Agarwal <br>
						Robert  M.   Gower<br>
						Romain      Mueller<br>
						Ruizhe      Li<br>
						Sadegh      Aliakbarian
					</div>
					<div class="col-4 col-12-xsmall">
						Safa        Alver<br>
						Shahab      Bakhtiari<br>
						Shangzhe    Wu<br>
						Sharath Chandra Raparthy<br>
						Steffen     Schneider<br>
						Steinar     Laenen<br>
						Taoli       Cheng<br>
						Tom     Joy<br>
						Udo M.   Schlegel<br>
						Victor      Schmidt<br>
						Vincent     Dumoulin<br>
						Vincent     Mai<br>
						Viveka      Kulharia<br>
						Xavier      Gibert<br>
						Xutan       Peng<br>
						Yana        Hasson<br>
						Yongtuo     Liu<br>
						Yuge        Shi<br>
						Yuki    M.   Asano<br>
						Yunhua      Zhang<br>
						Zhao        Yang<br>
						Zhongdao    Wang
					</div>
				</div>
			</div>
		</section>

		<!-- ------------------------------------------------------------------------------------------------------->
        <section class="main style1">
			<div class="container">
				<header class="major special">
					<h2>Previous editions</h2>
				</header>
				<div class="container">
					<p>
                        This is the third edition of the workshop. Below you can find previous years' pages.<br>
						In particular, <a href="http://proceedings.mlr.press/v148/">here</a> you can find the PMLR proceedings of the final papers (proposal+experiments) from last year's edition.
					</p>

                    <ul class="actions special">
                        <li><a href="https://preregister.science/neurips2020.html" class="button primary">NeurIPS 2020 workshop</a></li>
                        <li><a href="https://preregister.vision" class="button">ICCV 2019 workshop</a></li>
                    </ul>
                </div>
			</div>
		</section>
		
		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style2" id="instructions">
			<div class="container">
				<header class="major">
					<h2>FAQs</h2>
				</header>
				<ul class="spacious">
					<li><strong>Don't we need a positive publication bias? After all, there are many more ideas that don't work than ones that do. Why is it useful to allow negative results?</strong><br>
						There are several benefits to publishing negative results.  If an idea is well-motivated and intuitively appealing, it may be needlessly repeated by multiple groups who replicate the negative outcome, but do not have a venue for sharing this knowledge with the community (see the CVPR 2017 workshop on <a href="http://negative.vision/">negative results</a> for a more detailed discussion of the benefits of publishing negative outcomes).
					</li>
					<li><strong>Doesn't prior work on existing benchmarks weaken my confirmatory experiments?</strong><br>
						Yes.  Each prior result reported on a dataset leaks information that reduces its statistical utility (we are strongly in favour of limited-evaluation benchmarks for this reason).  Unfortunately, from a pragmatic perspective, it is infeasible to expect every machine learning researcher to collect a new dataset for each hypothesis they wish to evaluate, so we must strike a reasonable balance here.
					</li>
					<li><strong>Is it OK to make changes to the preregistered experimental protocol?</strong><br>
						Although you should endeavour to follow the proposed experimental protocol as closely as possible, you may find that it is necessary to make small changes or refinements.  These changes should be carefully documented when reporting the experimental results: it is important to make clear which protocols have been modified after observing the evidence.
					</li>
					<li><strong>What prevents authors from secretly running experiments, and submitting a proposal omitting them?</strong><br>
						We cannot fully prevent unethical practices, but this is a risky strategy. The reviewers assume that no experiments were ran yet, so they can request significant changes to the protocol. This means that there is a significant chance those results cannot be used.
					</li>
					<li><strong>How does exploratory data analysis fit into this model?</strong><br>
						Exploratory analysis can come in multiple forms including:
						(1) Small scale experiments (typically on toy data);
						(2) Results listed in prior work.
						Both should be reported in the proposal paper as part of the justification for your idea. Neither should be considered by the reader of your paper as providing <em>confirmatory evidence</em> in support of your hypothesis (the goal of preregistration is to make this distinction explicit). By contrast, the confirmatory experimental protocol which you propose should seek to rigorously evaluate your hypothesis and must be performed on different data to your own exploratory experiments. However, for practical reasons, it may use datasets that have also been previously used in the literature (further discussion below).
					</li>
					<li><strong>What's the rationale for changing the review model?</strong><br>
						&ldquo;Pre-for having a look.registration separates hypothesis-generating  (exploratory) from hypothesis-testing (confirmatory) research. Both are important. But the same data should not be used to generate and test a hypothesis, which can happen unintentionally and reduces the credibility of your results. Addressing this problem through planning improves the quality and transparency of your research, helping others who may wish to build on it.&rdquo; (source: <a href="https://cos.io/prereg/">cos.io</a>)
					</li>
					<li><strong>Where can I found more information about preregistration?</strong><br>
						There are a number of good resources for further reading around the ideas related to preregistration, including, but not limited to:
						<ul>
							<li><a href="https://www.pnas.org/content/115/11/2600">The preregistration revolution</a></li>
							<li><a href="https://www.nature.com/articles/s41562-016-0021">A manifesto for reproducible science</a></li>
							<li><a href="https://arxiv.org/abs/1904.10922">The Scientific Method in the Science of Machine Learning</a></li>
							<li><a href="https://cos.io/prereg/">The Center for Open Science</a> which includes a tool for preregistration and many more resources for further reading.
						</ul>
					</li>
                    <!--
					<li><strong>I have read the tutorial. Can you point me to a concrete example of a ML paper written with this spirit in mind?</strong><br>
						<a href="https://preregister.vision/papers/an_empirical_study_of_the_relation_between_network_architecture_and_complexity.pdf"><i>An empirical study of the relation between network architecture and complexity</i></a>, by Emir Konuk & Kevin Smith, won the best paper award at the pilot we run at ICCV 2019.
					</li>
                    <li><strong>Can the author list change from the proposal to the results paper?</strong><br>
                        New author(s) can be added for their contribution at the hypothesis testing phase, e.g., running the experiments.
                    </li>
					<li><strong>Does my proposal paper require the "Broader Impacts" section introduced by NeurIPS?</strong><br>
						A dedicated Broader Impacts section is not a required component of the proposal paper.
					</li>
					<li><strong>I see an option for supplementary material in CMT - is it necessary to submit any additional material for this?</strong><br>
						By default, it is not assumed that supplementary material will be required for the proposal paper.  However, it is available as an option to cover unusual use-cases (e.g. if the authors wish to refer to a video, or other forms of media).
					</li>
                    -->
				</ul>
			</div>
		</section>

		<!-- ------------------------------------------------------------------------------------------------------->
		<section class="main style1 special">
			<div class="container">
				<header class="major">
					<h2>Questions?</h2>
				</header>
				<ul class="actions special">
					<li><a href="mailto:preregistration2021@googlegroups.com" class="button wide primary">Contact us</a></li>
				</ul>
			</div>
		</section>

		<!-- Footer -->
		<section id="footer">
			<h3><strong>Share with friends who <span class="icon fa-heart-o"></span> science:</strong></h3>
		<ul class="icons">
		<li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fpreregister.science" target="_blank" class="icon alt fa-twitter"><span class="label">Twitter</span></a></li>
		<li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fpreregister.science" target="_blank" class="icon alt fa-facebook"><span class="label">Facebook</span></a></li>
		<li><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fpreregister.science" target="_blank" class="icon alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
		<li><a href="mailto:?subject=NeurIPS 2020 Workshop on Pre-registration&body=https%3A%2F%2Fpreregister.science" class="icon alt fa-envelope"><span class="label">Share by e-mail</span></a></li>
		</ul>
		<ul class="copyright">
		<li>&copy; Visual Geometry Group</li>
		<li>Design: <a href="http://html5up.net" target="_blank">HTML5 UP</a></li>
		<li>Photo: <a href="https://unsplash.com/photos/I_LgQ8JZFGE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Jo&atilde;o Silas</a></li>
		</ul>
		</section>

		<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/jquery.scrolly.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
		<script>
			// record original UTC time as data-utc attribute
			let schedule = document.getElementById("schedule");
			for (let i = 1; i < schedule.rows.length; i++) {
				let cell = schedule.rows[i].cells[0];
				cell.dataset.utc = cell.innerText;
			}

			function change_timezone(event_or_offset) {
				let offset = 0;
				if (typeof event_or_offset === 'number')
					offset = event_or_offset;  // passed an offset directly as a number (at initialization)
				else
					// get the selected offset by chopping off the "UTC" prefix from the
					// selected string, and interpreting the rest as an int
					offset = parseInt(event_or_offset.target.value.slice(3));

				// change the timezone to the given integer offset, by editing the table
				for (let j = 1; j < schedule.rows.length; j++) {
					let cell = schedule.rows[j].cells[0];  // table cell
					let parts = cell.dataset.utc.split(':');  // split hours:minutes from original stored UTC time
					let new_hour = parseInt(parts[0]) + offset;  // add offset to the original UTC time
					let suffix = "";
					if (new_hour >= 24) {  // wrap around
						new_hour -= 24;
						suffix = " (next day)";
					}
					if (new_hour < 0){
						new_hour += 24;
						suffix = " (prev. day)";
					}
					parts[0] = new_hour.toString();
					cell.innerText = parts.join(':') + suffix;
				}
			}

			// create and populate the dropdown
			let timezone_select = document.createElement("select");
			let timezone_wrapper = document.getElementById("schedule-timezone");
			let span = document.createElement("span");
			span.innerText = "Time";
			timezone_wrapper.innerHTML = "";
			timezone_wrapper.appendChild(span);
			timezone_wrapper.appendChild(timezone_select);
			for (let i = -12; i <= 12; i++) {
				let option = document.createElement("option");
				if (i >= 0)
					option.text = "UTC+" + i.toString();
				else
					option.text = "UTC" + i.toString();  // has a minus
				timezone_select.appendChild(option);
			}
			timezone_select.addEventListener('change', change_timezone);

			// initialize with the local UTC offset, and update the table
			let utc_offset_hours = -(new Date().getTimezoneOffset()) / 60;
			timezone_select.selectedIndex = utc_offset_hours + 12;
			change_timezone(utc_offset_hours);
		</script>

	</body>
</html>
